{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from shapely.wkt import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import geopandas as gpd\n",
    "from dbfread import DBF\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.error import HTTPError\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/18 12:23:22 WARN Utils: Your hostname, hexiangyideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.13.177.117 instead (on interface en0)\n",
      "22/10/18 12:23:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/18 12:23:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/18 12:23:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Tutorial 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Download SA2 2021 information\n",
    "url = \"https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SA2_2021_AUST_SHP_GDA2020.zip\" \n",
    "# year-month.parquet\n",
    "output_dir = \"../data/outer/2021sa2_shapefile.zip\"\n",
    "# download\n",
    "urlretrieve(url, output_dir) \n",
    "print(\"complete\")\n",
    "\n",
    "files = zipfile.ZipFile('../data/outer/2021sa2_shapefile.zip','r')\n",
    "for file in files.namelist():\n",
    "    files.extract(file, f\"../data/outer/2021sa2_shapefile\")\n",
    "\n",
    "# Download shapefile for each SA2 region\n",
    "def get_shapefile(url):\n",
    "    geojson_option = \"?_profile=oai&_mediatype=application/geo+json\"\n",
    "    try:\n",
    "        shape = str(gpd.read_file(url + geojson_option).iat[0,-1])\n",
    "    except HTTPError:\n",
    "        shape = \"\"\n",
    "    return shape\n",
    "\n",
    "get_shapefile_udf = udf(lambda a: get_shapefile(a),StringType())\n",
    "\n",
    "path = r'../data/outer/2021sa2_shapefile/SA2_2021_AUST_GDA2020.dbf' \n",
    "table = DBF(path)\n",
    "sa2_pd_temp = pd.DataFrame(iter(table))\n",
    "sa2_2021_temp = spark.createDataFrame(sa2_pd_temp) \n",
    "\n",
    "sa2_2021_vic = sa2_2021_temp.filter(F.col(\"STE_NAME21\")==\"Victoria\")\n",
    "sa2_2021_vic_w_geo = sa2_2021_vic.withColumn(\"geometry\", get_shapefile_udf(F.col(\"LOCI_URI21\")))\n",
    "sa2_2021_vic_w_geo = sa2_2021_vic_w_geo.select(\"SA2_CODE21\", \"SA2_NAME21\", \"geometry\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa2_2021_vic_w_geo = spark.read.parquet(\"../data/curated/sa2_2021_vic_w_geo.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "geospark = sa2_2021_vic_w_geo\n",
    "census = spark.read.parquet('../data/curated/final_census.parquet')\n",
    "vic_data = geospark.join(census, geospark.SA2_CODE21 == census.SA2_CODE_2021, \"left\").drop(census.SA2_CODE_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SA2 to do the visualizaton\n",
    "def visualisation(col_name, vic_data,geospark, title):\n",
    "    data = vic_data.groupBy(\"SA2_CODE21\").agg(F.avg(col_name).alias(col_name))\n",
    "    pdf = geospark.select(\"SA2_CODE21\", \"geometry\").toPandas()\n",
    "    pdf['geometry'] = gpd.GeoSeries.from_wkt(pdf['geometry'])\n",
    "    gdf = gpd.GeoDataFrame(pdf, geometry='geometry')\n",
    "    geoJSON = gdf[['SA2_CODE21', 'geometry']].drop_duplicates('SA2_CODE21').to_json()\n",
    "    m = folium.Map(location=[-37.84, 144.95], tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "    # refer to the folium documentations on how to plot aggregated data.\n",
    "    c = folium.Choropleth(\n",
    "        geo_data=geoJSON, # geoJSON \n",
    "        name='choropleth', # name of plot\n",
    "        data=data.toPandas(), # data source\n",
    "        columns=['SA2_CODE21',col_name], # the columns required\n",
    "        key_on='properties.SA2_CODE21', # this is from the geoJSON's properties\n",
    "        fill_color='YlOrRd', # color scheme\n",
    "        nan_fill_color='black',\n",
    "        legend_name=title\n",
    "    )\n",
    "\n",
    "    map = c.add_to(m)\n",
    "\n",
    "    map.save('../plots/foliumChoropleth_'+col_name+'.html')\n",
    "    map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the postcode, draw the proportion of the age group between 20-64 in total number of people in that region and the proportion of people earning above the Australian weekly median income ($1200) to the total number of people. The darker the color on the geo graph, the higher the percentage and the higher the consumption level of the people in the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.==>              (6 + 2) / 8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hexiangyi/opt/anaconda3/envs/ads/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/hexiangyi/opt/anaconda3/envs/ads/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/hexiangyi/opt/anaconda3/envs/ads/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hexiangyi/Desktop/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/geovisualisation.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hexiangyi/Desktop/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/geovisualisation.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m visualisation(\u001b[39m\"\u001b[39;49m\u001b[39mincome_percentage\u001b[39;49m\u001b[39m\"\u001b[39;49m, vic_data, geospark,\u001b[39m\"\u001b[39;49m\u001b[39mpercentage of people above medium income by SA2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexiangyi/Desktop/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/geovisualisation.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m visualisation(\u001b[39m\"\u001b[39m\u001b[39mage_percentage\u001b[39m\u001b[39m\"\u001b[39m, vic_data, geospark,\u001b[39m\"\u001b[39m\u001b[39mage percentage between 25-60\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/Users/hexiangyi/Desktop/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/geovisualisation.ipynb Cell 9\u001b[0m in \u001b[0;36mvisualisation\u001b[0;34m(col_name, vic_data, geospark, title)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexiangyi/Desktop/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/geovisualisation.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisualisation\u001b[39m(col_name, vic_data,geospark, title):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexiangyi/Desktop/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/geovisualisation.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     data \u001b[39m=\u001b[39m vic_data\u001b[39m.\u001b[39mgroupBy(\u001b[39m\"\u001b[39m\u001b[39mSA2_CODE21\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39magg(F\u001b[39m.\u001b[39mavg(col_name)\u001b[39m.\u001b[39malias(col_name))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hexiangyi/Desktop/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/geovisualisation.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pdf \u001b[39m=\u001b[39m geospark\u001b[39m.\u001b[39;49mselect(\u001b[39m\"\u001b[39;49m\u001b[39mSA2_CODE21\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgeometry\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mtoPandas()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexiangyi/Desktop/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/geovisualisation.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     pdf[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mGeoSeries\u001b[39m.\u001b[39mfrom_wkt(pdf[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hexiangyi/Desktop/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/geovisualisation.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     gdf \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39mGeoDataFrame(pdf, geometry\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ads/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:205\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m pdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_records(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect(), columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m    206\u001b[0m column_counter \u001b[39m=\u001b[39m Counter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m    208\u001b[0m corrected_dtypes: List[Optional[Type]] \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ads/lib/python3.8/site-packages/pyspark/sql/dataframe.py:817\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[39m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \n\u001b[1;32m    809\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sc):\n\u001b[0;32m--> 817\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mcollectToPython()\n\u001b[1;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ads/lib/python3.8/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ads/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ads/lib/python3.8/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ads/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "visualisation(\"income_percentage\", vic_data, geospark,\"percentage of people above medium income by SA2\")\n",
    "visualisation(\"age_percentage\", vic_data, geospark,\"age percentage between 25-60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ads')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e45bdfcba1031802b2f7a315f02d536e51553942a60e4ee4be74aec82814bfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
