{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import round\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/18 13:01:21 WARN Utils: Your hostname, Macintosh.local resolves to a loopback address: 127.0.0.1; using 10.12.240.133 instead (on interface en0)\n",
      "22/10/18 13:01:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/18 13:01:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/18 13:01:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Tutorial 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/Users/lydialyu/Documents/个人/1UoM/2 MAST30034 Applied Data Science/MAST30034 Assignment/Assignment 2/generic-buy-now-pay-later-project-group-16-project2-fighting-group/data/curated/prediction/predicted_dollar_value0.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lydialyu/Documents/个人/1UoM/2 MAST30034 Applied Data Science/MAST30034 Assignment/Assignment 2/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/Combine_table.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lydialyu/Documents/%E4%B8%AA%E4%BA%BA/1UoM/2%20MAST30034%20Applied%20Data%20Science/MAST30034%20Assignment/Assignment%202/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/Combine_table.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m census \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mparquet(\u001b[39m'\u001b[39m\u001b[39m../data/curated/final_census.parquet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lydialyu/Documents/%E4%B8%AA%E4%BA%BA/1UoM/2%20MAST30034%20Applied%20Data%20Science/MAST30034%20Assignment/Assignment%202/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/Combine_table.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m post_sa2_2021 \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mparquet(\u001b[39m\"\u001b[39m\u001b[39m../data/external/postcode_sa2_conrrespondences.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lydialyu/Documents/%E4%B8%AA%E4%BA%BA/1UoM/2%20MAST30034%20Applied%20Data%20Science/MAST30034%20Assignment/Assignment%202/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/Combine_table.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m prediction \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mparquet(\u001b[39m'\u001b[39;49m\u001b[39m../data/curated/prediction/predicted_dollar_value0.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lydialyu/Documents/%E4%B8%AA%E4%BA%BA/1UoM/2%20MAST30034%20Applied%20Data%20Science/MAST30034%20Assignment/Assignment%202/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/Combine_table.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Read all the prediction data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lydialyu/Documents/%E4%B8%AA%E4%BA%BA/1UoM/2%20MAST30034%20Applied%20Data%20Science/MAST30034%20Assignment/Assignment%202/generic-buy-now-pay-later-project-group-16-project2-fighting-group/notebooks/Combine_table.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m counts \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m45\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/readwriter.py:364\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    353\u001b[0m int96RebaseMode \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mint96RebaseMode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    354\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_opts(\n\u001b[1;32m    355\u001b[0m     mergeSchema\u001b[39m=\u001b[39mmergeSchema,\n\u001b[1;32m    356\u001b[0m     pathGlobFilter\u001b[39m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m     int96RebaseMode\u001b[39m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    362\u001b[0m )\n\u001b[0;32m--> 364\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mparquet(_to_seq(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_spark\u001b[39m.\u001b[39;49m_sc, paths)))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/Users/lydialyu/Documents/个人/1UoM/2 MAST30034 Applied Data Science/MAST30034 Assignment/Assignment 2/generic-buy-now-pay-later-project-group-16-project2-fighting-group/data/curated/prediction/predicted_dollar_value0.parquet"
     ]
    }
   ],
   "source": [
    "# read the tables\n",
    "transaction = spark.read.parquet('../data/curated/final_transaction.parquet')\n",
    "merchants = spark.read.parquet('../data/curated/final_merchant.parquet')\n",
    "consumer = spark.read.parquet('../data/curated/final_consumer.parquet')\n",
    "census = spark.read.parquet('../data/curated/final_census.parquet')\n",
    "post_sa2_2021 = spark.read.parquet(\"../data/external/postcode_sa2_conrrespondences.parquet\")\n",
    "prediction = spark.read.parquet('../data/curated/prediction/predicted_dollar_value0.parquet')\n",
    "# Read all the prediction data\n",
    "for counts in range(1,45):\n",
    "    counts =  str(counts)\n",
    "    prediction_add = spark.read.parquet(f\"../data/curated/prediction/predicted_dollar_value{counts}.parquet\")\n",
    "    prediction = prediction.union(prediction_add)\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>Amount</th><th>Count</th><th>count_of_bigorder</th></tr>\n",
       "<tr><td>10023283211</td><td>379547.6390727268</td><td>2121</td><td>0</td></tr>\n",
       "<tr><td>10142254217</td><td>48882.66543336331</td><td>1875</td><td>0</td></tr>\n",
       "<tr><td>10165489824</td><td>35623.68038836445</td><td>3</td><td>2</td></tr>\n",
       "<tr><td>10187291046</td><td>20254.487124206804</td><td>206</td><td>0</td></tr>\n",
       "<tr><td>10192359162</td><td>82759.73332280711</td><td>239</td><td>0</td></tr>\n",
       "<tr><td>10206519221</td><td>154924.2353959908</td><td>6090</td><td>0</td></tr>\n",
       "<tr><td>10255988167</td><td>164669.6631307207</td><td>531</td><td>0</td></tr>\n",
       "<tr><td>10264435225</td><td>296841.2830886513</td><td>3219</td><td>0</td></tr>\n",
       "<tr><td>10279061213</td><td>85417.56321640752</td><td>351</td><td>0</td></tr>\n",
       "<tr><td>10323485998</td><td>648209.1174973631</td><td>6638</td><td>0</td></tr>\n",
       "<tr><td>10342410215</td><td>171412.84048813253</td><td>562</td><td>0</td></tr>\n",
       "<tr><td>10346855916</td><td>10934.002484333816</td><td>7</td><td>0</td></tr>\n",
       "<tr><td>10364012396</td><td>7226.850814044746</td><td>24</td><td>0</td></tr>\n",
       "<tr><td>10385011947</td><td>14357.482993852966</td><td>23</td><td>0</td></tr>\n",
       "<tr><td>10385163239</td><td>14740.212192915878</td><td>49</td><td>0</td></tr>\n",
       "<tr><td>10385250025</td><td>178925.95795856853</td><td>437</td><td>0</td></tr>\n",
       "<tr><td>10404542215</td><td>22773.975280323484</td><td>1</td><td>1</td></tr>\n",
       "<tr><td>10430380319</td><td>30198.6017702329</td><td>103</td><td>0</td></tr>\n",
       "<tr><td>10441711491</td><td>14102.027224600944</td><td>3</td><td>0</td></tr>\n",
       "<tr><td>10462560289</td><td>23245.925763908628</td><td>1025</td><td>0</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------+------------------+-----+-----------------+\n",
       "|merchant_abn|            Amount|Count|count_of_bigorder|\n",
       "+------------+------------------+-----+-----------------+\n",
       "| 10023283211| 379547.6390727268| 2121|                0|\n",
       "| 10142254217| 48882.66543336331| 1875|                0|\n",
       "| 10165489824| 35623.68038836445|    3|                2|\n",
       "| 10187291046|20254.487124206804|  206|                0|\n",
       "| 10192359162| 82759.73332280711|  239|                0|\n",
       "| 10206519221| 154924.2353959908| 6090|                0|\n",
       "| 10255988167| 164669.6631307207|  531|                0|\n",
       "| 10264435225| 296841.2830886513| 3219|                0|\n",
       "| 10279061213| 85417.56321640752|  351|                0|\n",
       "| 10323485998| 648209.1174973631| 6638|                0|\n",
       "| 10342410215|171412.84048813253|  562|                0|\n",
       "| 10346855916|10934.002484333816|    7|                0|\n",
       "| 10364012396| 7226.850814044746|   24|                0|\n",
       "| 10385011947|14357.482993852966|   23|                0|\n",
       "| 10385163239|14740.212192915878|   49|                0|\n",
       "| 10385250025|178925.95795856853|  437|                0|\n",
       "| 10404542215|22773.975280323484|    1|                1|\n",
       "| 10430380319|  30198.6017702329|  103|                0|\n",
       "| 10441711491|14102.027224600944|    3|                0|\n",
       "| 10462560289|23245.925763908628| 1025|                0|\n",
       "+------------+------------------+-----+-----------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group the tables, get the number of big order per merchant\n",
    "grouped_transaction = transaction.groupBy('merchant_abn').agg(\n",
    "    F.sum('dollar_value').alias('Amount'), F.count('dollar_value').alias('Count'), \n",
    "    F.sum('whether_bigorder').alias('count_of_bigorder')).sort('merchant_abn')\n",
    "grouped_transaction.drop(F.col('order_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the monthly average features\n",
    "f = open(\"../data/number_of_months.txt\", \"r\")\n",
    "number_of_months = int(f.read())\n",
    "\n",
    "grouped_transaction = grouped_transaction.withColumn('Avg_amount_monthly', round(grouped_transaction['Amount']/number_of_months, 2))\n",
    "grouped_transaction = grouped_transaction.withColumn('Avg_count_monthly', round(grouped_transaction['Count']/number_of_months, 2))\n",
    "grouped_transaction = grouped_transaction.withColumn('Order_avg_value', round(grouped_transaction.Amount/grouped_transaction.Count,2))\n",
    "grouped_transaction = grouped_transaction.drop('Amount','Count')\n",
    "# Add monthly average features into merchants data\n",
    "merchant_data1 = merchants.join(grouped_transaction, merchants.merchant_abn == grouped_transaction.merchant_abn).drop(grouped_transaction.merchant_abn)\n",
    "merchant_data1 = merchant_data1.drop('Amount','Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the transaction data calculate each customer's fraud data\n",
    "ori_transaction_1 = transaction.groupby('merchant_abn','user_id').agg(\n",
    "    F.count('user_id').alias('count'), \n",
    "    F.avg('average_prob_con').alias('avg_prob_fraud_cus'),\n",
    "    F.avg('whether_fraud').alias('whether_fraud'))\n",
    "# Add the fraud data to merchants\n",
    "o_t = ori_transaction_1.groupby('merchant_abn').agg(\n",
    "    F.count('user_id').alias('cnt'), \n",
    "    F.avg('avg_prob_fraud_cus').alias('avg_prob_fraud_cus'),\n",
    "    F.sum('whether_fraud').alias('num_of_fraud'))\n",
    "# Calculate the probability of fraud customers among all customers\n",
    "cus_per_mon = o_t.withColumn('prob_of_fraud', o_t.num_of_fraud/o_t.cnt)\n",
    "cus_per_mon = cus_per_mon.withColumn('count_cus_per_mon', round(o_t['cnt']/number_of_months, 2))\n",
    "cus_per_mon = cus_per_mon.drop('cnt')\n",
    "cus_per_mon = cus_per_mon.drop('num_of_fraud')\n",
    "ori_transaction_2 = transaction.groupby('merchant_abn', 'user_id').count()\n",
    "# Calculate whether he/she is a regular customer\n",
    "ori_con_drop = ori_transaction_2.withColumn(\n",
    "    \"fixed_cus_num\",\n",
    "    F.when(F.col(\"count\") >= 5, 1).otherwise(0))\n",
    "# Calculate the number of the regular customer\n",
    "ori_con_fix = ori_con_drop.groupby('merchant_abn').agg(F.sum('fixed_cus_num').alias('fix_cus_num'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine the customer information into merchants\n",
    "user_info = cus_per_mon.join(ori_con_fix, cus_per_mon.merchant_abn == ori_con_fix.merchant_abn).drop(ori_con_fix.merchant_abn)\n",
    "user_info = user_info.drop('total_cus_num')\n",
    "merchant_abn_and_consumer_id = transaction['merchant_abn', 'user_id']\n",
    "user_id_and_postcode = consumer[['postcode','user_id']]\n",
    "merchant_and_consumer_postcode = merchant_abn_and_consumer_id.join(user_id_and_postcode,['user_id'])\n",
    "merchant_and_consumer_postcode = merchant_and_consumer_postcode['merchant_abn', 'postcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guess the merchants' postcode\n",
    "# https://stackoverflow.com/questions/36654162/mode-of-grouped-data-in-pyspark\n",
    "counts = merchant_and_consumer_postcode.groupBy(['merchant_abn', 'postcode']).count().alias('counts')\n",
    "merchant_postcode = (counts\n",
    "          .groupBy('merchant_abn')\n",
    "          .agg(F.max(F.struct(F.col('count'),\n",
    "                              F.col('postcode'))).alias('max'))\n",
    "          .select(F.col('merchant_abn'), F.col('max.postcode'))\n",
    "         )\n",
    "# Add census information into merchants\n",
    "merchant_info = merchant_data1.join(merchant_postcode, merchant_data1.merchant_abn == merchant_postcode.merchant_abn).drop(merchant_data1.merchant_abn)\n",
    "post_census = post_sa2_2021.join(census, post_sa2_2021.SA2_CODE_2021 == census.SA2_CODE_2021).drop(census.SA2_CODE_2021)\n",
    "post_census_1 = post_census.groupBy('postcode')\\\n",
    ".agg(F.avg(F.col('income_percentage')).alias(\"avg_income_percentage\"),\n",
    "F.avg(F.col('age_percentage')).alias('avg_age_percentage'))\n",
    "post_census_2 = post_census_1.select(post_census_1.postcode.cast('int'),post_census_1.avg_income_percentage, post_census_1.avg_age_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:>   (0 + 8) / 9][Stage 63:>   (0 + 0) / 9][Stage 64:>   (0 + 0) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/17 13:27:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:52 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:>   (0 + 8) / 9][Stage 64:>   (0 + 0) / 9][Stage 65:>   (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>   (0 + 8) / 9][Stage 65:>   (0 + 0) / 1][Stage 66:> (0 + 0) / 180]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/17 13:27:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/17 13:27:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:57 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:58 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>   (0 + 8) / 8][Stage 72:>   (0 + 0) / 9][Stage 74:>   (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "22/10/17 13:27:59 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "semifinal = merchant_info.join(user_info, merchant_info.merchant_abn == user_info.merchant_abn).drop(merchant_info.merchant_abn)\n",
    "final = semifinal.join(post_census_2, semifinal.postcode == post_census_2.postcode, 'left').drop(post_census_2.postcode)\n",
    "final = final.na.fill(value=0,subset=[\"avg_income_percentage\", \"avg_age_percentage\"])\n",
    "# Change take rate into predicted revenue for the BNPL companies\n",
    "final = final.withColumn('Take_rate', final.Take_rate*final.Avg_amount_monthly)\n",
    "final = final.join(prediction, final.merchant_abn == prediction.merchant_abn).drop(prediction.merchant_abn)\n",
    "final.write.mode('overwrite').parquet('../data/curated/merchant_info.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
